{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques of High Performance Computing - Assignment 2\n",
    "\n",
    "### Name: John Duffy\n",
    "\n",
    "### Student Number: 19154676"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT NOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries common to Questions 1 & 2.\n",
    "\n",
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "\n",
    "from scipy.sparse import csr_matrix, eye\n",
    "from scipy.sparse.linalg import LinearOperator, cg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "## OpenCL CSR Matrix-Vector Product\n",
    "\n",
    "**IMPORTANT NOTE**\n",
    "\n",
    "My MacBook Pro is equipped with an Intel Core i5 CPU and an Intel Iris Plus Graphics GPU as depicted below.\n",
    "\n",
    "    cl.get_platforms()[0].get_devices()\n",
    "\n",
    "    [<pyopencl.Device 'Intel(R) Core(TM) i5-8279U CPU @ 2.40GHz' on 'Apple' at 0xffffffff>,\n",
    "     <pyopencl.Device 'Intel(R) Iris(TM) Plus Graphics 655' on 'Apple' at 0x1024500>]\n",
    "     \n",
    "To ensure a context is created using the CPU for Question 1 (so that AVX2 technology is available) the function cl.Context() is used as below.\n",
    "\n",
    "    ctx = cl.Context(dev_type = cl.device_type.CPU)  # Tell OpenCL to use the CPU device.\n",
    "    \n",
    "The function cl.get_some_context() used in the course lecture notes is not specific enough (on my MacBook Pro at least) which then causes kernel build problems. This seems to be specific to macOS 10.14 Mojave.\n",
    "\n",
    "### Program Description\n",
    "\n",
    "This program...\n",
    "\n",
    "\n",
    "### Optimisation Results\n",
    "\n",
    "A class LinearOperatorBaseline was created to use as a baseline for measuring the performance gains through subsequnt use of OpenCL and AVX2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class LinearOperatorBaseline for baseline performance measurements.\n",
    "\n",
    "class LinearOperatorBaseline(LinearOperator):\n",
    "    \"\"\"\n",
    "    This class... \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, indices, indptr):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.indices = indices\n",
    "        self.indptr = indptr\n",
    "        self.shape = (len(indptr) - 1, len(indptr) - 1)  # Assume N x N.\n",
    "    \n",
    "    def _matvec(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        y = np.zeros(x.shape[0], dtype=np.float64)\n",
    "        \n",
    "        for i in range(self.shape[1]): \n",
    "            y[i] = np.dot(self.data[self.indptr[i]:self.indptr[i + 1]], x[self.indices[self.indptr[i]]:self.indptr[i + 1]])\n",
    "            \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test instance of LinearOperatorBaseline.\n",
    "\n",
    "N = 1000\n",
    "\n",
    "csr = eye((N), dtype=np.float64).tocsr()\n",
    "\n",
    "linear_operator = LinearOperatorBaseline(csr.data, csr.indices, csr.indptr)\n",
    "\n",
    "v = np.full((N), 5, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "#linear_operator.matvec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "#linear_operator * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_operator.matvec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_operator * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class LinearOperatorOpenCL.\n",
    "\n",
    "class LinearOperatorOpenCL(LinearOperator):\n",
    "    \"\"\"\n",
    "    This class... \n",
    "    \n",
    "    \n",
    "    Note: This class assumes the CSR matrix is N x N and derives N from the length of indptr parameter.   \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, indices, indptr):\n",
    "        \"\"\"\n",
    "        This function...\n",
    "        \"\"\"\n",
    "        \n",
    "        self.shape = (len(indptr) - 1, len(indptr) - 1)\n",
    "        \n",
    "        self.ctx = cl.Context(dev_type = cl.device_type.CPU)\n",
    "        \n",
    "        self.queue = cl.CommandQueue(self.ctx, properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "        \n",
    "        mf = cl.mem_flags\n",
    "        \n",
    "        # Copy the CSR matrix data to the device.\n",
    " \n",
    "        self.device_global_data = cl.Buffer(self.ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = data)\n",
    "        self.device_global_indices = cl.Buffer(self.ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = indices)       \n",
    "        self.device_global_indptr = cl.Buffer(self.ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf = indptr)\n",
    "\n",
    "        # Reserve space on the device for the input and output vectors.\n",
    "        \n",
    "        self.device_global_v = cl.Buffer(self.ctx, mf.READ_ONLY, size=self.shape[0] * np.dtype(np.float64).itemsize)\n",
    "        self.device_global_y = cl.Buffer(self.ctx, mf.WRITE_ONLY, size=self.shape[0] * np.dtype(np.float64).itemsize)\n",
    "\n",
    "        self.program = cl.Program(self.ctx, \"\"\"\n",
    "        __kernel void matvec_opencl(\n",
    "            __global const double *data,\n",
    "            __global const double *indices,\n",
    "            __global const double *indptr,\n",
    "            __global const double *v,\n",
    "            __global double *y\n",
    "        )\n",
    "        {\n",
    "            double8 result[4] = {0.0, 0.0, 0.0, 0.0};\n",
    " \n",
    "            int gid = get_global_id(0);\n",
    " \n",
    "            y[gid] = 10 * v[gid]; \n",
    "\n",
    "        }\n",
    "        \"\"\").build()\n",
    "\n",
    "    \n",
    "    def _matvec(self, host_v):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        cl.enqueue_copy(self.queue, self.device_global_v, host_v)\n",
    "\n",
    "        self.program.matvec_opencl(self.queue, \\\n",
    "                                   (self.shape[0],), \\\n",
    "                                   (1,), \\\n",
    "                                   self.device_global_data, \\\n",
    "                                   self.device_global_indices, \\\n",
    "                                   self.device_global_indptr, \\\n",
    "                                   self.device_global_v, \\\n",
    "                                   self.device_global_y \\\n",
    "                                  )\n",
    "\n",
    "        host_y = np.zeros((self.shape[0]), dtype=np.float64)\n",
    "\n",
    "        cl.enqueue_copy(self.queue, host_y, self.device_global_y)\n",
    "        \n",
    "               \n",
    "        #for i in range(self.shape[1]): \n",
    "        #y[i] = np.dot(self.data[self.indptr[i]:self.indptr[i + 1]], x[self.indices[self.indptr[i]]:self.indptr[i + 1]])\n",
    "            \n",
    "        return host_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test instance of LinearOperatorOpenCL.\n",
    "\n",
    "N = 16\n",
    "\n",
    "csr = eye((N), dtype=np.float64).tocsr()\n",
    "\n",
    "linear_operator = LinearOperatorOpenCL(csr.data, csr.indices, csr.indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([330., 330., 330., 330., 330., 330., 330., 330., 330., 330., 330.,\n",
       "       330., 330., 330., 330., 330.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the instance.\n",
    "\n",
    "v = np.full((N), 33, dtype=np.float64)\n",
    "\n",
    "linear_operator.matvec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "#linear_operator.matvec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "#linear_operator * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_operator.matvec(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_operator * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "## Solving a Poisson Problem with OpenCL\n",
    "\n",
    "**IMPORTANT NOTE**\n",
    "\n",
    "My MacBook Pro is equipped with an Intel Core i5 CPU and an Intel Iris Plus Graphics GPU as depicted below.\n",
    "\n",
    "    cl.get_platforms()[0].get_devices()\n",
    "\n",
    "    [<pyopencl.Device 'Intel(R) Core(TM) i5-8279U CPU @ 2.40GHz' on 'Apple' at 0xffffffff>,\n",
    "     <pyopencl.Device 'Intel(R) Iris(TM) Plus Graphics 655' on 'Apple' at 0x1024500>]\n",
    "     \n",
    "To ensure a context is created using the GPU for Question 2 the function cl.Context() is used as below.\n",
    "\n",
    "    ctx = cl.Context(dev_type = cl.device_type.GPU)  # Tell OpenCL to use the GPU device.\n",
    "    \n",
    "The function cl.get_some_context() used in the course lecture notes is not specific enough (on my MacBook Pro at least) which then causes kernel build problems. This seems to be specific to macOS 10.14 Mojave.\n",
    "\n",
    "### Program Description\n",
    "\n",
    "This program..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class StencilOperatorOpenCL.\n",
    "\n",
    "class StencilOperatorOpenCL(LinearOperator):\n",
    "    \"\"\"\n",
    "    This class... \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, m):\n",
    "        \"\"\"\n",
    "        This function...\n",
    "        \"\"\"\n",
    "        \n",
    "        self.shape = (m * m, m * m)\n",
    "        \n",
    "        self.ctx = cl.Context(dev_type = cl.device_type.GPU)\n",
    "        \n",
    "        self.queue = cl.CommandQueue(self.ctx, properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "        \n",
    "        mf = cl.mem_flags\n",
    "        \n",
    "        self.device_u = cl.Buffer(self.ctx, mf.READ_ONLY, size = self.shape[0] * np.dtype(np.float32).itemsize)\n",
    "        self.device_v = cl.Buffer(self.ctx, mf.WRITE_ONLY, size = self.shape[0] * np.dtype(np.float32).itemsize)\n",
    "\n",
    "        self.program = cl.Program(self.ctx, \"\"\"\n",
    "        __kernel void stencil_kernel(\n",
    "            __global const double *u,\n",
    "            __global double *v\n",
    "        )\n",
    "        {\n",
    "            //int i = get_global_id(0);\n",
    "            \n",
    "            //v[i] = 0.5 * u[i];\n",
    "\n",
    "            int i = get_global_id(0);\n",
    "            int j = get_global_id(1);\n",
    "            \n",
    "            // TODO: FIX\n",
    "            \n",
    "            int m = 4;\n",
    " \n",
    "            v[i * m + j] = 4 * u[i * m + j] - u[i * m + j - 1] - u[i * m + j + 1] - u[(i - 1) * m + j] - u[(i + 1) * m + j];\n",
    "            \n",
    "        }\n",
    "        \"\"\").build()\n",
    "\n",
    "    \n",
    "    def _matvec(self, u):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dtype = u.dtype\n",
    "        \n",
    "        cl.enqueue_copy(self.queue, self.device_u, u)\n",
    "\n",
    "        self.program.stencil_kernel(self.queue, \\\n",
    "                                   #(self.shape[0],), \\\n",
    "                                   (4, 4), \\\n",
    "                                   (1, 1), \\\n",
    "                                   self.device_u, \\\n",
    "                                   self.device_v)\n",
    "\n",
    "        v = np.zeros((self.shape[0]), dtype=np.float32)\n",
    "\n",
    "        cl.enqueue_copy(self.queue, v, self.device_v)\n",
    "            \n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of StencilOperatorOpenCL.\n",
    "\n",
    "M = 4\n",
    "\n",
    "stencil = StencilOperatorOpenCL(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8., 4., 4., 4., 0., 0., 0., 0., 0., 0., 0., 0., 4., 4., 4., 8.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the instance.\n",
    "\n",
    "u = np.full((M * M), 4, dtype=np.float32)\n",
    "\n",
    "stencil.matvec(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9182156 3.1078067 3.1078067 3.1078067]\n",
      " [4.2973976 4.2973976 4.2973976 4.2973976]\n",
      " [4.2973976 4.2973976 4.2973976 4.2973976]\n",
      " [3.1078067 3.1078067 3.1078067 1.9182156]]\n",
      "[[1.81532   2.3909163 2.7214108 3.0519052]\n",
      " [3.6275015 4.2884903 4.2884903 4.2884903]\n",
      " [4.2884903 4.2884903 4.2884903 3.6275015]\n",
      " [3.0519052 2.7214108 2.3909163 1.81532  ]]\n",
      "[[1.5426618 1.9647415 2.2689774 2.5732133]\n",
      " [2.995293  3.105226  3.8530345 3.603765 ]\n",
      " [3.603765  3.8530345 3.1052263 2.995293 ]\n",
      " [2.5732133 2.2689774 1.9647415 1.5426618]]\n",
      "[[1.2500279 1.6360278 2.0043201 2.0411484]\n",
      " [2.4271483 2.553068  2.7232718 2.9151354]\n",
      " [2.9151354 2.7232718 2.5530682 2.4271483]\n",
      " [2.0411487 2.0043201 1.6360279 1.2500279]]\n",
      "[[1.2394785 1.6712418 1.8299952 2.038436 ]\n",
      " [2.389145  2.5768006 2.6554084 2.7185879]\n",
      " [2.7185879 2.6554084 2.5768008 2.389145 ]\n",
      " [2.0384362 1.8299953 1.6712419 1.2394785]]\n"
     ]
    }
   ],
   "source": [
    "# Use Conjugate Iteration.\n",
    "\n",
    "M = 4\n",
    "\n",
    "u = np.full((M * M), 4, dtype=np.float32)\n",
    "\n",
    "#u = np.array([[0,0,0,0],[0,1,1,0],[0,1,1,0],[0,0,0,0]], dtype=np.float32).flatten()\n",
    "\n",
    "b = np.ones((M * M), dtype=np.float32)\n",
    "\n",
    "def cg_callback(xk):\n",
    "    print(xk.reshape(M, M))\n",
    "\n",
    "solution, info = cg(StencilOperatorOpenCL(N), b, x0 = u, maxiter = 5, callback = cg_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2394785, 1.6712418, 1.8299952, 2.038436 ],\n",
       "       [2.389145 , 2.5768006, 2.6554084, 2.7185879],\n",
       "       [2.7185879, 2.6554084, 2.5768008, 2.389145 ],\n",
       "       [2.0384362, 1.8299953, 1.6712419, 1.2394785]], dtype=float32)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.reshape(M, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
